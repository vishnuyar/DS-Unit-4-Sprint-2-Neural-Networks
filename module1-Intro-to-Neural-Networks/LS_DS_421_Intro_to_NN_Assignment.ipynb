{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer:\n",
        "### Hidden Layer:\n",
        "### Output Layer:\n",
        "### Neuron:\n",
        "### Weight:\n",
        "### Activation Function:\n",
        "### Node Map:\n",
        "### Perceptron:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "#### Your Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7M9U41tzJbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e3b71be8-b88a-4f06-9b7e-001ca0f94a4f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')\n",
        "df['bias'] = 1\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  y  bias\n",
              "0   0   0  1     1\n",
              "1   1   0  1     1\n",
              "2   0   1  1     1\n",
              "3   1   1  0     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc0JXxSWzJbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def der_sigmoid(x):\n",
        "  sx = sigmoid(x)\n",
        "  return sx*(1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBa8rq5wz8Ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2fb5b406-03db-4448-c0bf-874352c1489b"
      },
      "source": [
        "inputs = df[['x1','x2','bias']].values\n",
        "outputs = df['y'].values\n",
        "inputs,outputs"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 1],\n",
              "        [1, 0, 1],\n",
              "        [0, 1, 1],\n",
              "        [1, 1, 1]]), array([1, 1, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvIafTHN3QOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utz6jL5p2eXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1837a21-9df7-4e4d-8fc0-a337a770c253"
      },
      "source": [
        "weights = np.random.rand(3)\n",
        "error_rsm = 100\n",
        "\n",
        "for i in range(10000):\n",
        "  weighted_sum = np.dot(inputs,weights)\n",
        "  activated = sigmoid(weighted_sum)\n",
        "  error = outputs - activated\n",
        "  \n",
        "  adjusted = error*der_sigmoid(error)\n",
        "  weights += np.dot(inputs.T,adjusted)\n",
        "  error_rsm = mean_squared_error(outputs,activated)**(0.5)\n",
        "  if (i%100==0):\n",
        "    print(f'Iteration:{i}, RMSE :{error_rsm:0.5f}, yhat:{activated}')\n",
        "print(f'weights:{weights}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:0, RMSE :0.47954, yhat:[0.65994604 0.70042147 0.78922474 0.8185435 ]\n",
            "Iteration:100, RMSE :0.15258, yhat:[0.99125311 0.84832149 0.84922103 0.21750415]\n",
            "Iteration:200, RMSE :0.09087, yhat:[0.99852765 0.90903077 0.90907492 0.12840093]\n",
            "Iteration:300, RMSE :0.06399, yhat:[0.99953366 0.93581239 0.93581787 0.09023022]\n",
            "Iteration:400, RMSE :0.04915, yhat:[0.99979969 0.95066423 0.95066536 0.06924148]\n",
            "Iteration:500, RMSE :0.03980, yhat:[0.99989713 0.96003586 0.96003618 0.05604432]\n",
            "Iteration:600, RMSE :0.03339, yhat:[0.9999406  0.96646305 0.96646316 0.04700995]\n",
            "Iteration:700, RMSE :0.02873, yhat:[0.99996276 0.97113447 0.97113452 0.04045049]\n",
            "Iteration:800, RMSE :0.02520, yhat:[0.99997517 0.97467805 0.97467807 0.03547803]\n",
            "Iteration:900, RMSE :0.02244, yhat:[0.99998265 0.97745559 0.9774556  0.03158228]\n",
            "Iteration:1000, RMSE :0.02021, yhat:[0.99998741 0.97968976 0.97968976 0.02844967]\n",
            "Iteration:1100, RMSE :0.01839, yhat:[0.99999059 0.98152489 0.9815249  0.02587717]\n",
            "Iteration:1200, RMSE :0.01686, yhat:[0.99999278 0.98305858 0.98305858 0.02372763]\n",
            "Iteration:1300, RMSE :0.01557, yhat:[0.99999435 0.98435909 0.98435909 0.02190516]\n",
            "Iteration:1400, RMSE :0.01445, yhat:[0.99999549 0.98547559 0.98547559 0.02034073]\n",
            "Iteration:1500, RMSE :0.01349, yhat:[0.99999635 0.98644439 0.98644439 0.01898338]\n",
            "Iteration:1600, RMSE :0.01265, yhat:[0.999997   0.98729285 0.98729285 0.01779472]\n",
            "Iteration:1700, RMSE :0.01190, yhat:[0.99999751 0.988042   0.988042   0.01674527]\n",
            "Iteration:1800, RMSE :0.01124, yhat:[0.9999979  0.98870824 0.98870824 0.015812  ]\n",
            "Iteration:1900, RMSE :0.01064, yhat:[0.99999822 0.98930457 0.98930457 0.01497671]\n",
            "Iteration:2000, RMSE :0.01011, yhat:[0.99999848 0.9898414  0.9898414  0.01422479]\n",
            "Iteration:2100, RMSE :0.00963, yhat:[0.99999869 0.99032718 0.99032718 0.01354438]\n",
            "Iteration:2200, RMSE :0.00919, yhat:[0.99999886 0.99076885 0.99076885 0.01292579]\n",
            "Iteration:2300, RMSE :0.00878, yhat:[0.99999901 0.99117213 0.99117213 0.01236098]\n",
            "Iteration:2400, RMSE :0.00842, yhat:[0.99999913 0.99154181 0.99154181 0.01184324]\n",
            "Iteration:2500, RMSE :0.00808, yhat:[0.99999923 0.9918819  0.9918819  0.01136695]\n",
            "Iteration:2600, RMSE :0.00777, yhat:[0.99999932 0.99219582 0.99219582 0.01092733]\n",
            "Iteration:2700, RMSE :0.00748, yhat:[0.99999939 0.99248645 0.99248645 0.01052032]\n",
            "Iteration:2800, RMSE :0.00721, yhat:[0.99999945 0.9927563  0.9927563  0.01014242]\n",
            "Iteration:2900, RMSE :0.00696, yhat:[0.99999951 0.99300751 0.99300751 0.00979063]\n",
            "Iteration:3000, RMSE :0.00672, yhat:[0.99999956 0.99324194 0.99324194 0.00946234]\n",
            "Iteration:3100, RMSE :0.00651, yhat:[0.9999996  0.99346122 0.99346122 0.00915527]\n",
            "Iteration:3200, RMSE :0.00630, yhat:[0.99999964 0.99366676 0.99366676 0.00886744]\n",
            "Iteration:3300, RMSE :0.00611, yhat:[0.99999967 0.99385982 0.99385982 0.0085971 ]\n",
            "Iteration:3400, RMSE :0.00593, yhat:[0.9999997 0.9940415 0.9940415 0.0083427]\n",
            "Iteration:3500, RMSE :0.00576, yhat:[0.99999972 0.99421276 0.99421276 0.00810288]\n",
            "Iteration:3600, RMSE :0.00560, yhat:[0.99999975 0.99437449 0.99437449 0.00787641]\n",
            "Iteration:3700, RMSE :0.00545, yhat:[0.99999977 0.99452745 0.99452745 0.00766223]\n",
            "Iteration:3800, RMSE :0.00530, yhat:[0.99999978 0.99467233 0.99467233 0.00745935]\n",
            "Iteration:3900, RMSE :0.00516, yhat:[0.9999998  0.99480976 0.99480976 0.00726691]\n",
            "Iteration:4000, RMSE :0.00503, yhat:[0.99999982 0.9949403  0.9949403  0.00708412]\n",
            "Iteration:4100, RMSE :0.00491, yhat:[0.99999983 0.99506446 0.99506446 0.00691028]\n",
            "Iteration:4200, RMSE :0.00479, yhat:[0.99999984 0.99518268 0.99518268 0.00674474]\n",
            "Iteration:4300, RMSE :0.00468, yhat:[0.99999985 0.99529538 0.99529538 0.00658693]\n",
            "Iteration:4400, RMSE :0.00457, yhat:[0.99999986 0.99540295 0.99540295 0.00643632]\n",
            "Iteration:4500, RMSE :0.00447, yhat:[0.99999987 0.99550571 0.99550571 0.00629242]\n",
            "Iteration:4600, RMSE :0.00437, yhat:[0.99999988 0.995604   0.995604   0.0061548 ]\n",
            "Iteration:4700, RMSE :0.00428, yhat:[0.99999989 0.99569809 0.99569809 0.00602306]\n",
            "Iteration:4800, RMSE :0.00419, yhat:[0.99999989 0.99578824 0.99578824 0.00589683]\n",
            "Iteration:4900, RMSE :0.00410, yhat:[0.9999999  0.9958747  0.9958747  0.00577576]\n",
            "Iteration:5000, RMSE :0.00402, yhat:[0.99999991 0.9959577  0.9959577  0.00565956]\n",
            "Iteration:5100, RMSE :0.00394, yhat:[0.99999991 0.99603742 0.99603742 0.00554793]\n",
            "Iteration:5200, RMSE :0.00387, yhat:[0.99999992 0.99611407 0.99611407 0.00544061]\n",
            "Iteration:5300, RMSE :0.00379, yhat:[0.99999992 0.99618781 0.99618781 0.00533735]\n",
            "Iteration:5400, RMSE :0.00372, yhat:[0.99999993 0.99625882 0.99625882 0.00523794]\n",
            "Iteration:5500, RMSE :0.00365, yhat:[0.99999993 0.99632723 0.99632723 0.00514215]\n",
            "Iteration:5600, RMSE :0.00359, yhat:[0.99999993 0.99639319 0.99639319 0.00504979]\n",
            "Iteration:5700, RMSE :0.00353, yhat:[0.99999994 0.99645683 0.99645683 0.00496069]\n",
            "Iteration:5800, RMSE :0.00346, yhat:[0.99999994 0.99651826 0.99651826 0.00487467]\n",
            "Iteration:5900, RMSE :0.00341, yhat:[0.99999994 0.99657761 0.99657761 0.00479158]\n",
            "Iteration:6000, RMSE :0.00335, yhat:[0.99999995 0.99663497 0.99663497 0.00471127]\n",
            "Iteration:6100, RMSE :0.00329, yhat:[0.99999995 0.99669044 0.99669044 0.0046336 ]\n",
            "Iteration:6200, RMSE :0.00324, yhat:[0.99999995 0.99674412 0.99674412 0.00455844]\n",
            "Iteration:6300, RMSE :0.00319, yhat:[0.99999995 0.99679608 0.99679608 0.00448568]\n",
            "Iteration:6400, RMSE :0.00314, yhat:[0.99999996 0.99684642 0.99684642 0.00441521]\n",
            "Iteration:6500, RMSE :0.00309, yhat:[0.99999996 0.9968952  0.9968952  0.0043469 ]\n",
            "Iteration:6600, RMSE :0.00304, yhat:[0.99999996 0.9969425  0.9969425  0.00428068]\n",
            "Iteration:6700, RMSE :0.00300, yhat:[0.99999996 0.99698838 0.99698838 0.00421644]\n",
            "Iteration:6800, RMSE :0.00295, yhat:[0.99999996 0.99703291 0.99703291 0.0041541 ]\n",
            "Iteration:6900, RMSE :0.00291, yhat:[0.99999996 0.99707614 0.99707614 0.00409357]\n",
            "Iteration:7000, RMSE :0.00287, yhat:[0.99999997 0.99711813 0.99711813 0.00403478]\n",
            "Iteration:7100, RMSE :0.00283, yhat:[0.99999997 0.99715894 0.99715894 0.00397765]\n",
            "Iteration:7200, RMSE :0.00279, yhat:[0.99999997 0.9971986  0.9971986  0.00392211]\n",
            "Iteration:7300, RMSE :0.00275, yhat:[0.99999997 0.99723718 0.99723718 0.0038681 ]\n",
            "Iteration:7400, RMSE :0.00271, yhat:[0.99999997 0.99727471 0.99727471 0.00381555]\n",
            "Iteration:7500, RMSE :0.00268, yhat:[0.99999997 0.99731123 0.99731123 0.00376441]\n",
            "Iteration:7600, RMSE :0.00264, yhat:[0.99999997 0.9973468  0.9973468  0.00371462]\n",
            "Iteration:7700, RMSE :0.00261, yhat:[0.99999997 0.99738143 0.99738143 0.00366613]\n",
            "Iteration:7800, RMSE :0.00257, yhat:[0.99999998 0.99741517 0.99741517 0.00361889]\n",
            "Iteration:7900, RMSE :0.00254, yhat:[0.99999998 0.99744806 0.99744806 0.00357284]\n",
            "Iteration:8000, RMSE :0.00251, yhat:[0.99999998 0.99748012 0.99748012 0.00352796]\n",
            "Iteration:8100, RMSE :0.00248, yhat:[0.99999998 0.99751138 0.99751138 0.00348418]\n",
            "Iteration:8200, RMSE :0.00245, yhat:[0.99999998 0.99754188 0.99754188 0.00344148]\n",
            "Iteration:8300, RMSE :0.00242, yhat:[0.99999998 0.99757165 0.99757165 0.00339981]\n",
            "Iteration:8400, RMSE :0.00239, yhat:[0.99999998 0.9976007  0.9976007  0.00335913]\n",
            "Iteration:8500, RMSE :0.00236, yhat:[0.99999998 0.99762906 0.99762906 0.00331942]\n",
            "Iteration:8600, RMSE :0.00233, yhat:[0.99999998 0.99765677 0.99765677 0.00328063]\n",
            "Iteration:8700, RMSE :0.00230, yhat:[0.99999998 0.99768383 0.99768383 0.00324274]\n",
            "Iteration:8800, RMSE :0.00228, yhat:[0.99999998 0.99771028 0.99771028 0.00320571]\n",
            "Iteration:8900, RMSE :0.00225, yhat:[0.99999998 0.99773613 0.99773613 0.00316951]\n",
            "Iteration:9000, RMSE :0.00223, yhat:[0.99999998 0.9977614  0.9977614  0.00313413]\n",
            "Iteration:9100, RMSE :0.00220, yhat:[0.99999998 0.99778612 0.99778612 0.00309952]\n",
            "Iteration:9200, RMSE :0.00218, yhat:[0.99999999 0.9978103  0.9978103  0.00306567]\n",
            "Iteration:9300, RMSE :0.00216, yhat:[0.99999999 0.99783396 0.99783396 0.00303255]\n",
            "Iteration:9400, RMSE :0.00213, yhat:[0.99999999 0.99785711 0.99785711 0.00300014]\n",
            "Iteration:9500, RMSE :0.00211, yhat:[0.99999999 0.99787977 0.99787977 0.00296841]\n",
            "Iteration:9600, RMSE :0.00209, yhat:[0.99999999 0.99790196 0.99790196 0.00293734]\n",
            "Iteration:9700, RMSE :0.00207, yhat:[0.99999999 0.99792369 0.99792369 0.00290692]\n",
            "Iteration:9800, RMSE :0.00204, yhat:[0.99999999 0.99794497 0.99794497 0.00287712]\n",
            "Iteration:9900, RMSE :0.00202, yhat:[0.99999999 0.99796582 0.99796582 0.00284792]\n",
            "weights:[-12.07418301 -12.07418301  18.27992766]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MstZcgLvzJbX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "67773cb9-058e-47ef-b72c-0fdb481635f8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error \n",
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diabetes.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyqvsJOKzJbb",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfzSli_jHxMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00f7c32e-9b99-4b56-c766-ecc3d2036869"
      },
      "source": [
        "X = diabetes[diabetes.columns.drop('Outcome')]\n",
        "y = diabetes['Outcome']\n",
        "X.shape,y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((768, 8), (768,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEQAJUQMHM7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55c303fa-e1b6-468a-fdd8-99623ac58f96"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,stratify=y)\n",
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((691, 8), (77, 8), (691,), (77,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdZPlhiEzJbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "708b9735-030c-40f8-e371-a135626d3727"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "x = Normalizer().fit_transform(X_train)\n",
        "y = y_train.values.reshape(y_train.shape[0],1)\n",
        "x.shape,y.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((691, 8), (691, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W0tiX1F1hh2",
        "colab": {}
      },
      "source": [
        "##### Update this Class #####\n",
        "\n",
        "class Perceptron(object):\n",
        "    \n",
        "    def __init__(self, niter = 10):\n",
        "      self.niter = niter\n",
        "    \n",
        "    def __sigmoid(self, x):\n",
        "        return 1/(1+np.exp(-x))\n",
        "    \n",
        "    def __sigmoid_derivative(self, x):\n",
        "        sx = self.__sigmoid(x)\n",
        "        return sx*(1-sx)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      \"\"\"Fit training data\n",
        "      X : Training vectors, X.shape : [#samples, #features]\n",
        "      y : Target values, y.shape : [#samples]\n",
        "      \"\"\"\n",
        "      #creating bias unit\n",
        "      onesarray = np.ones(X.shape[0]).reshape(X.shape[0],1)\n",
        "      # Adding bias unit to input values\n",
        "      X = np.hstack([onesarray,X])\n",
        "      print(X.shape[1])\n",
        "\n",
        "      # Randomly Initialize Weights\n",
        "      self.weights = 2*np.random.rand(X.shape[1],1) - 1\n",
        "\n",
        "      for i in range(self.niter):\n",
        "          # Weighted sum of inputs / weights\n",
        "\n",
        "          # Activate!\n",
        "\n",
        "          # Cac error\n",
        "\n",
        "          # Update the Weights\n",
        "          weighted_sum = np.dot(X,self.weights)\n",
        "          self.activated = self.__sigmoid(weighted_sum)\n",
        "          self.error = y - self.activated\n",
        "          adjusted = self.error*self.__sigmoid_derivative(self.error)\n",
        "          self.weights += np.dot(X.T,adjusted)\n",
        "          error_rsm = mean_squared_error(y,self.activated)**(0.5)\n",
        "          if (i%10==0):\n",
        "            print(f'Iteration:{i}, RMSE :{error_rsm:0.5f}')\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "      \"\"\"Return class label after unit step\"\"\"\n",
        "      return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNadIaxSh_g2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68ac86f1-3da4-4ba3-e22c-d9ddc57f2944"
      },
      "source": [
        "max(pp.activated)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.08928705e-24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L23HE8wJhjgI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3c262ca5-04f3-4bd1-dbb9-a6613807aa65"
      },
      "source": [
        "pp = Perceptron(100)\n",
        "pp.fit(x,y)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "Iteration:0, RMSE :0.50836\n",
            "Iteration:10, RMSE :0.59045\n",
            "Iteration:20, RMSE :0.80699\n",
            "Iteration:30, RMSE :0.59057\n",
            "Iteration:40, RMSE :0.58314\n",
            "Iteration:50, RMSE :0.79836\n",
            "Iteration:60, RMSE :0.59057\n",
            "Iteration:70, RMSE :0.58583\n",
            "Iteration:80, RMSE :0.78292\n",
            "Iteration:90, RMSE :0.59057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7ByPcfRcVam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6b151854-f045-4eb9-a3a3-37ccb34016db"
      },
      "source": [
        "pp = Perceptron(100)\n",
        "pp.fit(x,y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "Iteration:0, RMSE :0.72544\n",
            "Iteration:10, RMSE :0.59057\n",
            "Iteration:20, RMSE :0.57487\n",
            "Iteration:30, RMSE :0.80520\n",
            "Iteration:40, RMSE :0.59057\n",
            "Iteration:50, RMSE :0.58430\n",
            "Iteration:60, RMSE :0.78874\n",
            "Iteration:70, RMSE :0.59057\n",
            "Iteration:80, RMSE :0.58525\n",
            "Iteration:90, RMSE :0.78250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}