{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BostonTraining\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 430\n",
      "Trainable params: 404\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating a model for training on boston housing dataset\n",
    "\n",
    "model = Sequential(name='BostonTraining')\n",
    "model.add(BatchNormalization(input_shape=(13,)))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.62225272032155"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean Squared Error for Base Prediction\n",
    "((y_train - y_train.mean())**2).sum()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples\n",
      "Epoch 1/10\n",
      "404/404 [==============================] - 1s 2ms/sample - loss: 458.8124\n",
      "Epoch 2/10\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 344.3006\n",
      "Epoch 3/10\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 185.5215\n",
      "Epoch 4/10\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 106.9888\n",
      "Epoch 5/10\n",
      "404/404 [==============================] - 0s 82us/sample - loss: 55.8387\n",
      "Epoch 6/10\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 37.1758\n",
      "Epoch 7/10\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 39.1429\n",
      "Epoch 8/10\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 31.2113\n",
      "Epoch 9/10\n",
      "404/404 [==============================] - 0s 84us/sample - loss: 65.1580\n",
      "Epoch 10/10\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 55.5669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f29c0152908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelfit = model.fit(x_train,y_train,epochs=10)\n",
    "modelfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BostonTraining_part2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 689\n",
      "Trainable params: 663\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='BostonTraining_part2')\n",
    "model.add(BatchNormalization(input_shape=(13,)))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples\n",
      "Epoch 1/10\n",
      "404/404 [==============================] - 1s 1ms/sample - loss: 2170302217521358.2500\n",
      "Epoch 2/10\n",
      "404/404 [==============================] - 0s 84us/sample - loss: 5114038705283.8018\n",
      "Epoch 3/10\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 3024418512490.4551\n",
      "Epoch 4/10\n",
      "404/404 [==============================] - 0s 83us/sample - loss: 1788626989258.7725\n",
      "Epoch 5/10\n",
      "404/404 [==============================] - 0s 83us/sample - loss: 1057785753316.1188\n",
      "Epoch 6/10\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 625569673256.5544\n",
      "Epoch 7/10\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 369958989215.6832\n",
      "Epoch 8/10\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 218792067072.0000\n",
      "Epoch 9/10\n",
      "404/404 [==============================] - 0s 82us/sample - loss: 129392641297.7426\n",
      "Epoch 10/10\n",
      "404/404 [==============================] - 0s 83us/sample - loss: 76522197073.1089\n"
     ]
    }
   ],
   "source": [
    "modelfit = model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BostonTraining_part3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 689\n",
      "Trainable params: 663\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='BostonTraining_part3')\n",
    "model.add(BatchNormalization(input_shape=(13,)))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples\n",
      "Epoch 1/100\n",
      "404/404 [==============================] - 1s 1ms/sample - loss: 470.3666\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s 94us/sample - loss: 351.5951\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 132.4696\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 112.3825\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 100.4168\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 114.6037\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s 84us/sample - loss: 103.3265\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 99.2931\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s 382us/sample - loss: 84.3910\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 89.5148\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 86.3744\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s 84us/sample - loss: 75.7678\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 77.4596\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 77.3810\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 58.6206\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s 107us/sample - loss: 77.3007\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 63.2409\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s 97us/sample - loss: 62.6713\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 61.3866\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 51.9704\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 66.0251\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 65.0019\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 58.0342\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 66.8644\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 53.5121\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 55.4630\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 53.0630\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 59.2584\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 61.7970\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 63.4189\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 63.0558\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 57.6634\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 57.4141\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 57.0183\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 60.3855\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 58.1156\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 58.6320\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 55.3631\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 55.8532\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 49.7310\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 55.4847\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s 98us/sample - loss: 50.0894\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s 94us/sample - loss: 57.2202\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 54.9229\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 59.5757\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 63.4054\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 53.8018\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 54.9452\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s 84us/sample - loss: 48.8783\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 56.0047\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 55.3610\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 57.5430\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 53.5901\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 48.6650\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 51.3100\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 53.4313\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 44.9355\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 48.9265\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 66.1078\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 54.0992\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 95us/sample - loss: 52.6861\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 49.9100\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s 94us/sample - loss: 50.1344\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s 95us/sample - loss: 45.8649\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 56.8130\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 49.1225\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 50.4590\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 46.2268\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 54.1516\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 46.2578\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s 138us/sample - loss: 51.3950\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 44.0940\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 48.5903\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 61.4089\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 54.8786\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 56.1866\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 50.7994\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 53.9626\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 49.5800\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s 83us/sample - loss: 55.7829\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 57.6549\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 45.5173\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 43.7149\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 47.6657\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 51.1269\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 53.6909\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 68.7764\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s 95us/sample - loss: 59.5500\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 63.2712\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s 83us/sample - loss: 55.9573\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s 83us/sample - loss: 59.2301\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 59.3094\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 60.6123\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 54.6739\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 53.0644\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 46.9522\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 53.0666\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 54.5890\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 52.9209\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 57.6087\n"
     ]
    }
   ],
   "source": [
    "modelfit = model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BostonTraining_simple\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 343\n",
      "Trainable params: 317\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='BostonTraining_simple')\n",
    "model.add(BatchNormalization(input_shape=(13,)))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/200\n",
      "404/404 [==============================] - 1s 2ms/sample - loss: 592.7198 - val_loss: 563.1751\n",
      "Epoch 2/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 588.8593 - val_loss: 568.2256\n",
      "Epoch 3/200\n",
      "404/404 [==============================] - 0s 123us/sample - loss: 581.9510 - val_loss: 569.1217\n",
      "Epoch 4/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 576.2820 - val_loss: 566.9879\n",
      "Epoch 5/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 571.9448 - val_loss: 563.7273\n",
      "Epoch 6/200\n",
      "404/404 [==============================] - 0s 124us/sample - loss: 564.6642 - val_loss: 558.1784\n",
      "Epoch 7/200\n",
      "404/404 [==============================] - 0s 122us/sample - loss: 558.8431 - val_loss: 551.6272\n",
      "Epoch 8/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 547.5137 - val_loss: 542.7597\n",
      "Epoch 9/200\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 536.6928 - val_loss: 531.4443\n",
      "Epoch 10/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 531.5320 - val_loss: 517.7738\n",
      "Epoch 11/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 508.8352 - val_loss: 500.1321\n",
      "Epoch 12/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 494.1471 - val_loss: 478.8593\n",
      "Epoch 13/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 458.3080 - val_loss: 452.4581\n",
      "Epoch 14/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 444.6306 - val_loss: 422.6319\n",
      "Epoch 15/200\n",
      "404/404 [==============================] - 0s 125us/sample - loss: 405.5273 - val_loss: 389.6632\n",
      "Epoch 16/200\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 382.9792 - val_loss: 351.9712\n",
      "Epoch 17/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 329.4925 - val_loss: 309.5663\n",
      "Epoch 18/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 319.1513 - val_loss: 267.5718\n",
      "Epoch 19/200\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 286.6821 - val_loss: 229.0960\n",
      "Epoch 20/200\n",
      "404/404 [==============================] - 0s 142us/sample - loss: 271.9766 - val_loss: 195.4931\n",
      "Epoch 21/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 250.3834 - val_loss: 170.8750\n",
      "Epoch 22/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 236.6495 - val_loss: 152.7392\n",
      "Epoch 23/200\n",
      "404/404 [==============================] - 0s 138us/sample - loss: 241.3317 - val_loss: 140.8308\n",
      "Epoch 24/200\n",
      "404/404 [==============================] - 0s 147us/sample - loss: 216.1257 - val_loss: 131.2920\n",
      "Epoch 25/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 207.8813 - val_loss: 121.3715\n",
      "Epoch 26/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 209.5884 - val_loss: 118.8568\n",
      "Epoch 27/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 201.8388 - val_loss: 114.7235\n",
      "Epoch 28/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 212.9197 - val_loss: 111.9554\n",
      "Epoch 29/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 200.7920 - val_loss: 109.6672\n",
      "Epoch 30/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 208.2364 - val_loss: 104.4972\n",
      "Epoch 31/200\n",
      "404/404 [==============================] - 0s 138us/sample - loss: 213.7295 - val_loss: 96.2062\n",
      "Epoch 32/200\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 194.5087 - val_loss: 93.0508\n",
      "Epoch 33/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 218.8882 - val_loss: 98.0384\n",
      "Epoch 34/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 215.9760 - val_loss: 98.8148\n",
      "Epoch 35/200\n",
      "404/404 [==============================] - 0s 124us/sample - loss: 189.2924 - val_loss: 97.5034\n",
      "Epoch 36/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 200.6167 - val_loss: 89.9904\n",
      "Epoch 37/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 222.8774 - val_loss: 85.8469\n",
      "Epoch 38/200\n",
      "404/404 [==============================] - 0s 141us/sample - loss: 182.9827 - val_loss: 87.3303\n",
      "Epoch 39/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 180.3519 - val_loss: 85.7431\n",
      "Epoch 40/200\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 199.6380 - val_loss: 86.8598\n",
      "Epoch 41/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 200.2803 - val_loss: 90.0248\n",
      "Epoch 42/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 185.2170 - val_loss: 85.2393\n",
      "Epoch 43/200\n",
      "404/404 [==============================] - 0s 149us/sample - loss: 179.5466 - val_loss: 86.2487\n",
      "Epoch 44/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 186.0536 - val_loss: 81.2583\n",
      "Epoch 45/200\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 191.3931 - val_loss: 79.1166\n",
      "Epoch 46/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 194.4143 - val_loss: 86.8894\n",
      "Epoch 47/200\n",
      "404/404 [==============================] - 0s 139us/sample - loss: 188.8454 - val_loss: 86.5218\n",
      "Epoch 48/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 169.2114 - val_loss: 80.5428\n",
      "Epoch 49/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 187.3030 - val_loss: 81.0798\n",
      "Epoch 50/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 188.1524 - val_loss: 80.5892\n",
      "Epoch 51/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 172.7323 - val_loss: 80.8259\n",
      "Epoch 52/200\n",
      "404/404 [==============================] - 0s 123us/sample - loss: 196.6347 - val_loss: 80.2687\n",
      "Epoch 53/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 169.6976 - val_loss: 77.4497\n",
      "Epoch 54/200\n",
      "404/404 [==============================] - 0s 123us/sample - loss: 165.8621 - val_loss: 77.6062\n",
      "Epoch 55/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 204.7809 - val_loss: 78.0115\n",
      "Epoch 56/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 184.6273 - val_loss: 76.5433\n",
      "Epoch 57/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 168.4280 - val_loss: 80.8554\n",
      "Epoch 58/200\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 218.1702 - val_loss: 81.7032\n",
      "Epoch 59/200\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 209.6090 - val_loss: 81.7970\n",
      "Epoch 60/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 168.0047 - val_loss: 83.3787\n",
      "Epoch 61/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 175.9774 - val_loss: 74.8335\n",
      "Epoch 62/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 181.3181 - val_loss: 74.5138\n",
      "Epoch 63/200\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 182.2933 - val_loss: 70.8903\n",
      "Epoch 64/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 170.1042 - val_loss: 72.8806\n",
      "Epoch 65/200\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 180.2323 - val_loss: 74.6578\n",
      "Epoch 66/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 166.1557 - val_loss: 77.8299\n",
      "Epoch 67/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 181.0837 - val_loss: 77.0164\n",
      "Epoch 68/200\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 170.0047 - val_loss: 72.6888\n",
      "Epoch 69/200\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 171.1506 - val_loss: 70.9261\n",
      "Epoch 70/200\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 195.6907 - val_loss: 72.1813\n",
      "Epoch 71/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 169.4442 - val_loss: 70.1777\n",
      "Epoch 72/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 196.8271 - val_loss: 70.8764\n",
      "Epoch 73/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 190.7396 - val_loss: 69.6627\n",
      "Epoch 74/200\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 166.2875 - val_loss: 74.4061\n",
      "Epoch 75/200\n",
      "404/404 [==============================] - 0s 150us/sample - loss: 150.0205 - val_loss: 69.9070\n",
      "Epoch 76/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 151.3165 - val_loss: 73.7156\n",
      "Epoch 77/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 183.5572 - val_loss: 76.3612\n",
      "Epoch 78/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 180.6080 - val_loss: 74.1680\n",
      "Epoch 79/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 160.4635 - val_loss: 67.1478\n",
      "Epoch 80/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 179.3649 - val_loss: 65.0546\n",
      "Epoch 81/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 183.1120 - val_loss: 68.1319\n",
      "Epoch 82/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 163.1883 - val_loss: 67.6610\n",
      "Epoch 83/200\n",
      "404/404 [==============================] - 0s 124us/sample - loss: 160.8177 - val_loss: 66.9162\n",
      "Epoch 84/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 179.8518 - val_loss: 65.7898\n",
      "Epoch 85/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 164.7865 - val_loss: 66.2547\n",
      "Epoch 86/200\n",
      "404/404 [==============================] - 0s 144us/sample - loss: 164.6772 - val_loss: 70.2292\n",
      "Epoch 87/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 157.2426 - val_loss: 66.4433\n",
      "Epoch 88/200\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 155.9131 - val_loss: 70.0467\n",
      "Epoch 89/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 169.5846 - val_loss: 67.7190\n",
      "Epoch 90/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 165.3715 - val_loss: 65.7395\n",
      "Epoch 91/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 156.3424 - val_loss: 64.0769\n",
      "Epoch 92/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 168.3743 - val_loss: 60.3388\n",
      "Epoch 93/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 161.6006 - val_loss: 64.5987\n",
      "Epoch 94/200\n",
      "404/404 [==============================] - 0s 124us/sample - loss: 198.6242 - val_loss: 61.9300\n",
      "Epoch 95/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 161.6453 - val_loss: 62.2339\n",
      "Epoch 96/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 157.8224 - val_loss: 63.2468\n",
      "Epoch 97/200\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 168.5266 - val_loss: 67.1965\n",
      "Epoch 98/200\n",
      "404/404 [==============================] - 0s 125us/sample - loss: 166.2216 - val_loss: 70.1164\n",
      "Epoch 99/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 149.8962 - val_loss: 69.1607\n",
      "Epoch 100/200\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 178.3438 - val_loss: 68.0366\n",
      "Epoch 101/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 160.8982 - val_loss: 63.7224\n",
      "Epoch 102/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 157.1347 - val_loss: 62.6805\n",
      "Epoch 103/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 154.4538 - val_loss: 66.9521\n",
      "Epoch 104/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 190.1801 - val_loss: 74.0715\n",
      "Epoch 105/200\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 156.0683 - val_loss: 68.6379\n",
      "Epoch 106/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 157.6692 - val_loss: 56.4184\n",
      "Epoch 107/200\n",
      "404/404 [==============================] - 0s 140us/sample - loss: 162.0165 - val_loss: 57.9035\n",
      "Epoch 108/200\n",
      "404/404 [==============================] - 0s 143us/sample - loss: 174.1922 - val_loss: 59.2735\n",
      "Epoch 109/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 174.9062 - val_loss: 64.4167\n",
      "Epoch 110/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 149.7997 - val_loss: 59.9841\n",
      "Epoch 111/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 155.9046 - val_loss: 58.0676\n",
      "Epoch 112/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 168.3567 - val_loss: 58.2449\n",
      "Epoch 113/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 162.1795 - val_loss: 61.6216\n",
      "Epoch 114/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 152.4651 - val_loss: 62.6101\n",
      "Epoch 115/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 160.3646 - val_loss: 57.8369\n",
      "Epoch 116/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 155.6053 - val_loss: 63.5445\n",
      "Epoch 117/200\n",
      "404/404 [==============================] - 0s 125us/sample - loss: 151.6894 - val_loss: 63.1952\n",
      "Epoch 118/200\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 176.1463 - val_loss: 65.2918\n",
      "Epoch 119/200\n",
      "404/404 [==============================] - 0s 145us/sample - loss: 150.4198 - val_loss: 62.8489\n",
      "Epoch 120/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 162.9955 - val_loss: 58.8881\n",
      "Epoch 121/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 132.3688 - val_loss: 53.0830\n",
      "Epoch 122/200\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 165.9344 - val_loss: 53.0514\n",
      "Epoch 123/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 155.0663 - val_loss: 54.7620\n",
      "Epoch 124/200\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 167.9881 - val_loss: 60.4690\n",
      "Epoch 125/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 127.4997 - val_loss: 66.8106\n",
      "Epoch 126/200\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 156.9076 - val_loss: 65.5111\n",
      "Epoch 127/200\n",
      "404/404 [==============================] - 0s 138us/sample - loss: 157.7287 - val_loss: 59.1033\n",
      "Epoch 128/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 186.4623 - val_loss: 58.5763\n",
      "Epoch 129/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 141.1200 - val_loss: 56.7432\n",
      "Epoch 130/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 148.9591 - val_loss: 54.5245\n",
      "Epoch 131/200\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 137.7057 - val_loss: 54.8989\n",
      "Epoch 132/200\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 148.6508 - val_loss: 57.4513\n",
      "Epoch 133/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 166.4841 - val_loss: 60.1096\n",
      "Epoch 134/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 135.6785 - val_loss: 60.8396\n",
      "Epoch 135/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 143.5632 - val_loss: 61.6345\n",
      "Epoch 136/200\n",
      "404/404 [==============================] - 0s 142us/sample - loss: 160.3735 - val_loss: 60.3985\n",
      "Epoch 137/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 171.5653 - val_loss: 57.2584\n",
      "Epoch 138/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 166.3543 - val_loss: 60.0589\n",
      "Epoch 139/200\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 166.8730 - val_loss: 58.7606\n",
      "Epoch 140/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 162.5116 - val_loss: 58.0058\n",
      "Epoch 141/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 177.1285 - val_loss: 55.4281\n",
      "Epoch 142/200\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 153.9494 - val_loss: 56.6012\n",
      "Epoch 143/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 157.7848 - val_loss: 60.8669\n",
      "Epoch 144/200\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 154.0781 - val_loss: 60.6688\n",
      "Epoch 145/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 156.2242 - val_loss: 57.5852\n",
      "Epoch 146/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 120.2603 - val_loss: 56.5189\n",
      "Epoch 147/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 171.6318 - val_loss: 55.3466\n",
      "Epoch 148/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 147.2912 - val_loss: 52.4485\n",
      "Epoch 149/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 142.3798 - val_loss: 50.0282\n",
      "Epoch 150/200\n",
      "404/404 [==============================] - 0s 197us/sample - loss: 174.1084 - val_loss: 52.1819\n",
      "Epoch 151/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 157.9598 - val_loss: 57.9241\n",
      "Epoch 152/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 142.0487 - val_loss: 55.5036\n",
      "Epoch 153/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 123.1042 - val_loss: 55.3941\n",
      "Epoch 154/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 158.8147 - val_loss: 59.1944\n",
      "Epoch 155/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 153.8804 - val_loss: 66.2502\n",
      "Epoch 156/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 161.4191 - val_loss: 61.4508\n",
      "Epoch 157/200\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 155.0321 - val_loss: 54.9758\n",
      "Epoch 158/200\n",
      "404/404 [==============================] - 0s 142us/sample - loss: 156.1966 - val_loss: 54.6757\n",
      "Epoch 159/200\n",
      "404/404 [==============================] - 0s 143us/sample - loss: 142.6110 - val_loss: 53.9891\n",
      "Epoch 160/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 147.0761 - val_loss: 52.9124\n",
      "Epoch 161/200\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 138.0400 - val_loss: 51.3423\n",
      "Epoch 162/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 164.0848 - val_loss: 50.9664\n",
      "Epoch 163/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 162.7763 - val_loss: 55.7887\n",
      "Epoch 164/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 162.7114 - val_loss: 54.9192\n",
      "Epoch 165/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 148.5344 - val_loss: 53.4513\n",
      "Epoch 166/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 110.0690 - val_loss: 53.9361\n",
      "Epoch 167/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 129.8098 - val_loss: 56.0927\n",
      "Epoch 168/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 147.7070 - val_loss: 59.1115\n",
      "Epoch 169/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 146.3480 - val_loss: 56.6891\n",
      "Epoch 170/200\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 147.1148 - val_loss: 55.5128\n",
      "Epoch 171/200\n",
      "404/404 [==============================] - 0s 143us/sample - loss: 123.6514 - val_loss: 54.2535\n",
      "Epoch 172/200\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 168.4581 - val_loss: 50.3845\n",
      "Epoch 173/200\n",
      "404/404 [==============================] - 0s 140us/sample - loss: 147.7570 - val_loss: 52.7930\n",
      "Epoch 174/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 140.9083 - val_loss: 53.1409\n",
      "Epoch 175/200\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 125.1814 - val_loss: 51.4271\n",
      "Epoch 176/200\n",
      "404/404 [==============================] - 0s 141us/sample - loss: 112.3485 - val_loss: 56.1893\n",
      "Epoch 177/200\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 136.8685 - val_loss: 52.6928\n",
      "Epoch 178/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 119.5912 - val_loss: 52.1424\n",
      "Epoch 179/200\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 183.3883 - val_loss: 52.4273\n",
      "Epoch 180/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 156.6004 - val_loss: 51.8813\n",
      "Epoch 181/200\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 143.7349 - val_loss: 52.5097\n",
      "Epoch 182/200\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 150.4962 - val_loss: 53.3405\n",
      "Epoch 183/200\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 126.1314 - val_loss: 56.2412\n",
      "Epoch 184/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 125.7057 - val_loss: 54.2078\n",
      "Epoch 185/200\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 131.6533 - val_loss: 53.5727\n",
      "Epoch 186/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 150.0870 - val_loss: 51.3708\n",
      "Epoch 187/200\n",
      "404/404 [==============================] - 0s 142us/sample - loss: 125.8708 - val_loss: 52.8373\n",
      "Epoch 188/200\n",
      "404/404 [==============================] - 0s 142us/sample - loss: 149.4322 - val_loss: 53.1699\n",
      "Epoch 189/200\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 145.4246 - val_loss: 53.2310\n",
      "Epoch 190/200\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 127.7725 - val_loss: 53.4363\n",
      "Epoch 191/200\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 143.9898 - val_loss: 54.6811\n",
      "Epoch 192/200\n",
      "404/404 [==============================] - 0s 139us/sample - loss: 146.0993 - val_loss: 55.3656\n",
      "Epoch 193/200\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 133.8098 - val_loss: 53.5185\n",
      "Epoch 194/200\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 153.8452 - val_loss: 54.8802\n",
      "Epoch 195/200\n",
      "404/404 [==============================] - 0s 139us/sample - loss: 144.8244 - val_loss: 51.5020\n",
      "Epoch 196/200\n",
      "404/404 [==============================] - 0s 139us/sample - loss: 140.2684 - val_loss: 48.0185\n",
      "Epoch 197/200\n",
      "404/404 [==============================] - 0s 143us/sample - loss: 130.8035 - val_loss: 48.2237\n",
      "Epoch 198/200\n",
      "404/404 [==============================] - 0s 143us/sample - loss: 135.1802 - val_loss: 50.2376\n",
      "Epoch 199/200\n",
      "404/404 [==============================] - 0s 145us/sample - loss: 129.6068 - val_loss: 51.3466\n",
      "Epoch 200/200\n",
      "404/404 [==============================] - 0s 140us/sample - loss: 109.4236 - val_loss: 54.5783\n"
     ]
    }
   ],
   "source": [
    "modelfit = model.fit(x_train,y_train,epochs=200,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train.shape,y_train.shape,x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct Encoding on Y\n",
    "# What softmax expects = [0,0,0,0,0,1,0,0,0,0]\n",
    "num_classes = 10\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FashionTraining_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 88,221\n",
      "Trainable params: 86,653\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='FashionTraining_1')\n",
    "model.add(BatchNormalization(input_shape=(784,)))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(25,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.7020 - accuracy: 0.7537 - val_loss: 0.4395 - val_accuracy: 0.8349\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.5127 - accuracy: 0.8229 - val_loss: 0.4135 - val_accuracy: 0.8461\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.4703 - accuracy: 0.8367 - val_loss: 0.3947 - val_accuracy: 0.8586\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.4452 - accuracy: 0.8463 - val_loss: 0.3864 - val_accuracy: 0.8582\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.4169 - accuracy: 0.8553 - val_loss: 0.3858 - val_accuracy: 0.8628\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.4085 - accuracy: 0.8581 - val_loss: 0.3619 - val_accuracy: 0.8712\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3967 - accuracy: 0.8614 - val_loss: 0.3532 - val_accuracy: 0.8702\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3796 - accuracy: 0.8673 - val_loss: 0.3598 - val_accuracy: 0.8734\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3738 - accuracy: 0.8683 - val_loss: 0.3707 - val_accuracy: 0.8677\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.3663 - accuracy: 0.8716 - val_loss: 0.3666 - val_accuracy: 0.8766\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.3632 - accuracy: 0.8732 - val_loss: 0.3449 - val_accuracy: 0.8766\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3513 - accuracy: 0.8764 - val_loss: 0.3546 - val_accuracy: 0.8782\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3468 - accuracy: 0.8777 - val_loss: 0.3516 - val_accuracy: 0.8760\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.3413 - accuracy: 0.8784 - val_loss: 0.3439 - val_accuracy: 0.8808\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3404 - accuracy: 0.8788 - val_loss: 0.3509 - val_accuracy: 0.8777\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3321 - accuracy: 0.8831 - val_loss: 0.3552 - val_accuracy: 0.8779\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3331 - accuracy: 0.8807 - val_loss: 0.3423 - val_accuracy: 0.8832\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3296 - accuracy: 0.8824 - val_loss: 0.3417 - val_accuracy: 0.8827\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.3227 - accuracy: 0.8844 - val_loss: 0.3490 - val_accuracy: 0.8833\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.3209 - accuracy: 0.8862 - val_loss: 0.3392 - val_accuracy: 0.8847\n"
     ]
    }
   ],
   "source": [
    "modelfit = model.fit(x_train,y_train,epochs=20,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
