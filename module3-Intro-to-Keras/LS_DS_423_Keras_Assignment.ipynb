{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BostonTraining\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 430\n",
      "Trainable params: 404\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating a model for training on boston housing dataset\n",
    "\n",
    "model = Sequential(name='BostonTraining')\n",
    "model.add(BatchNormalization(input_shape=(13,)))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.62225272032155"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean Squared Error for Base Prediction\n",
    "((y_train - y_train.mean())**2).sum()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples\n",
      "Epoch 1/10\n",
      "404/404 [==============================] - 0s 193us/sample - loss: 84.6555\n",
      "Epoch 2/10\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 84.7107\n",
      "Epoch 3/10\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 84.6754\n",
      "Epoch 4/10\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 84.6744\n",
      "Epoch 5/10\n",
      "404/404 [==============================] - 0s 94us/sample - loss: 84.6489\n",
      "Epoch 6/10\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 84.6696\n",
      "Epoch 7/10\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 84.6690\n",
      "Epoch 8/10\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 84.6770\n",
      "Epoch 9/10\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 84.6481\n",
      "Epoch 10/10\n",
      "404/404 [==============================] - 0s 102us/sample - loss: 84.6533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5db4487ef0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelfit = model.fit(x_train,y_train,epochs=10)\n",
    "modelfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BostonTraining_part2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 689\n",
      "Trainable params: 663\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='BostonTraining_part2')\n",
    "model.add(BatchNormalization(input_shape=(13,)))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples\n",
      "Epoch 1/10\n",
      "404/404 [==============================] - 0s 116us/sample - loss: 84.6678\n",
      "Epoch 2/10\n",
      "404/404 [==============================] - 0s 94us/sample - loss: 84.6805\n",
      "Epoch 3/10\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 84.6596\n",
      "Epoch 4/10\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 84.6568\n",
      "Epoch 5/10\n",
      "404/404 [==============================] - 0s 99us/sample - loss: 84.6797\n",
      "Epoch 6/10\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 84.6543\n",
      "Epoch 7/10\n",
      "404/404 [==============================] - 0s 83us/sample - loss: 84.7116\n",
      "Epoch 8/10\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 84.6565\n",
      "Epoch 9/10\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 84.6490\n",
      "Epoch 10/10\n",
      "404/404 [==============================] - 0s 97us/sample - loss: 84.6633\n"
     ]
    }
   ],
   "source": [
    "modelfit = model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BostonTraining_part3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_6 (Batch (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 689\n",
      "Trainable params: 663\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='BostonTraining_part3')\n",
    "model.add(BatchNormalization(input_shape=(13,)))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples\n",
      "Epoch 1/100\n",
      "404/404 [==============================] - 1s 2ms/sample - loss: 479.8873\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 315.0945\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s 99us/sample - loss: 112.8776\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 108us/sample - loss: 109.1346\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s 103us/sample - loss: 107.9367\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s 97us/sample - loss: 103.8074\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s 115us/sample - loss: 100.3139\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s 109us/sample - loss: 93.5553\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s 116us/sample - loss: 88.0684\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s 121us/sample - loss: 85.5305\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s 112us/sample - loss: 77.3365\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s 114us/sample - loss: 66.8614\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s 112us/sample - loss: 68.8958\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s 94us/sample - loss: 66.1744\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s 107us/sample - loss: 55.6699\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s 103us/sample - loss: 55.8425\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s 111us/sample - loss: 57.8682\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s 103us/sample - loss: 51.6629\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 50.0448\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 44.8291\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s 110us/sample - loss: 44.0615\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 99us/sample - loss: 47.6797\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s 102us/sample - loss: 49.9354\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s 112us/sample - loss: 60.7262\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s 115us/sample - loss: 49.0977\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 113us/sample - loss: 49.7158\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 46.2432\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s 106us/sample - loss: 51.7850\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s 99us/sample - loss: 45.3101\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 48.3364\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s 98us/sample - loss: 52.5909\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s 98us/sample - loss: 39.1830\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s 97us/sample - loss: 46.4191\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s 102us/sample - loss: 46.1679\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s 103us/sample - loss: 42.0553\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s 98us/sample - loss: 43.6151\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s 104us/sample - loss: 44.6101\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s 107us/sample - loss: 36.9128\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s 99us/sample - loss: 43.0590\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s 121us/sample - loss: 42.6673\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s 114us/sample - loss: 43.2237\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 47.7469\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s 100us/sample - loss: 40.9977\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s 99us/sample - loss: 41.3152\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s 108us/sample - loss: 46.7158\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 100us/sample - loss: 69.6748\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 47.2076\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s 99us/sample - loss: 54.5021\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s 110us/sample - loss: 61.6469\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s 125us/sample - loss: 66.6970\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s 115us/sample - loss: 58.8930\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s 120us/sample - loss: 78.7996\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 62.9684\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s 95us/sample - loss: 78.0966\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s 97us/sample - loss: 75.2561\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 106us/sample - loss: 61.0636\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s 106us/sample - loss: 62.7488\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s 111us/sample - loss: 57.0517\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 77.7902\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s 109us/sample - loss: 56.6786\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 107us/sample - loss: 52.6814\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 103us/sample - loss: 58.6907\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 57.7253\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 54.2641\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s 119us/sample - loss: 53.0783\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s 98us/sample - loss: 59.6073\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s 108us/sample - loss: 45.9020\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s 100us/sample - loss: 55.9585\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s 114us/sample - loss: 47.8655\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s 104us/sample - loss: 52.8647\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s 107us/sample - loss: 50.5474\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 49.1159\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 56.6020\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s 105us/sample - loss: 58.7354\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 97us/sample - loss: 56.2936\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 53.3511\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 50.6921\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 106us/sample - loss: 52.7182\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 107us/sample - loss: 52.1118\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s 110us/sample - loss: 58.0233\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 53.4534\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 111us/sample - loss: 56.0766\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 53.7067\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s 112us/sample - loss: 52.1582\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 110us/sample - loss: 52.1227\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s 103us/sample - loss: 52.7336\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 57.5456\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 51.9909\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 111us/sample - loss: 57.2607\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s 99us/sample - loss: 58.6748\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s 95us/sample - loss: 58.5200\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s 108us/sample - loss: 55.7521\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s 110us/sample - loss: 60.7949\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 112us/sample - loss: 55.6616\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 51.7203\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 54.0902\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 55.6955\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 58.2968\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 55.3312\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 103us/sample - loss: 56.0045\n"
     ]
    }
   ],
   "source": [
    "modelfit = model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BostonTraining_simple\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_8 (Batch (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 343\n",
      "Trainable params: 317\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='BostonTraining_simple')\n",
    "model.add(BatchNormalization(input_shape=(13,)))\n",
    "model.add(Dense(13,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/100\n",
      "404/404 [==============================] - 1s 2ms/sample - loss: 516.8063 - val_loss: 302.6898\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 167.5718 - val_loss: 97.5470\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 143.4226 - val_loss: 88.6227\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 136.7103 - val_loss: 94.9073\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 125.0276 - val_loss: 85.2291\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 126.0804 - val_loss: 99.7672\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 113.9335 - val_loss: 95.2066\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 339.0919 - val_loss: 152.1459\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s 122us/sample - loss: 123.6967 - val_loss: 88.8379\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s 122us/sample - loss: 109.5560 - val_loss: 87.9786\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 102.9945 - val_loss: 88.7004\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s 124us/sample - loss: 105.3566 - val_loss: 91.3266\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 99.2088 - val_loss: 79.0382\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 93.4699 - val_loss: 77.0992\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 90.0113 - val_loss: 70.1674\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 92.6488 - val_loss: 82.1300\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s 139us/sample - loss: 79.1780 - val_loss: 70.7031\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 85.5022 - val_loss: 66.6026\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s 124us/sample - loss: 83.0237 - val_loss: 66.1707\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 81.0704 - val_loss: 67.0642\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 74.1315 - val_loss: 62.4091\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 84.1289 - val_loss: 71.2306\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 83.7251 - val_loss: 69.1348\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 78.8790 - val_loss: 65.0740\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 80.5653 - val_loss: 66.7348\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 77.3445 - val_loss: 65.5841\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 75.8847 - val_loss: 63.7411\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s 122us/sample - loss: 72.8883 - val_loss: 61.0865\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 75.7690 - val_loss: 60.1489\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 76.3736 - val_loss: 62.3614\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 76.1324 - val_loss: 60.6682\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s 123us/sample - loss: 72.6181 - val_loss: 55.8225\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 68.6469 - val_loss: 58.4084\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 71.7798 - val_loss: 56.2975\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 73.9322 - val_loss: 57.8978\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s 124us/sample - loss: 76.2670 - val_loss: 66.7730\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s 119us/sample - loss: 71.4374 - val_loss: 54.2203\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s 174us/sample - loss: 69.8672 - val_loss: 57.2743\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 74.2622 - val_loss: 57.6817\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s 137us/sample - loss: 77.8184 - val_loss: 61.8553\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 64.9948 - val_loss: 49.8590\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s 124us/sample - loss: 71.9195 - val_loss: 59.0805\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 74.2335 - val_loss: 55.4756\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s 139us/sample - loss: 67.9222 - val_loss: 52.8926\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 67.8907 - val_loss: 49.6243\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 124us/sample - loss: 73.7352 - val_loss: 55.8107\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 62.7032 - val_loss: 46.8137\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s 123us/sample - loss: 67.2993 - val_loss: 49.4598\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 64.2249 - val_loss: 47.2522\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 64.2854 - val_loss: 67.3777\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 67.7831 - val_loss: 52.0072\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 85.1459 - val_loss: 88.3376\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 88.7782 - val_loss: 87.5225\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s 124us/sample - loss: 87.9631 - val_loss: 86.7856\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 83.6098 - val_loss: 84.6679\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 122us/sample - loss: 82.4731 - val_loss: 90.8361\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 83.2358 - val_loss: 83.5532\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 85.1932 - val_loss: 80.6903\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 81.6092 - val_loss: 75.4428\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 83.8479 - val_loss: 83.7260\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 85.5155 - val_loss: 83.4954\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 84.7891 - val_loss: 84.5051\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 86.0586 - val_loss: 85.0432\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 85.1587 - val_loss: 84.6573\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 86.3218 - val_loss: 84.4382\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 85.4338 - val_loss: 83.6071\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s 125us/sample - loss: 86.0407 - val_loss: 84.9014\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 85.1346 - val_loss: 84.3076\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s 138us/sample - loss: 85.0530 - val_loss: 83.7185\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 84.6919 - val_loss: 83.3913\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 85.4302 - val_loss: 83.6095\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s 125us/sample - loss: 84.9486 - val_loss: 84.0140\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s 123us/sample - loss: 84.4509 - val_loss: 83.6292\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 84.9046 - val_loss: 83.7828\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 85.2164 - val_loss: 83.9058\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 85.0618 - val_loss: 83.9736\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 84.9328 - val_loss: 83.7757\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 84.9741 - val_loss: 83.7082\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 84.9817 - val_loss: 83.4935\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 84.8540 - val_loss: 83.9698\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 84.8025 - val_loss: 84.0307\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 85.0265 - val_loss: 83.8957\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 85.0721 - val_loss: 84.2262\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 84.9593 - val_loss: 83.9998\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 84.5748 - val_loss: 83.5447\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s 132us/sample - loss: 84.9575 - val_loss: 83.9799\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 136us/sample - loss: 84.9063 - val_loss: 83.9786\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s 138us/sample - loss: 84.7777 - val_loss: 83.7352\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 131us/sample - loss: 84.7793 - val_loss: 83.5819\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 84.7419 - val_loss: 83.6078\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s 129us/sample - loss: 84.6584 - val_loss: 83.6105\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 84.8715 - val_loss: 83.7132\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s 130us/sample - loss: 84.8524 - val_loss: 83.7938\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 135us/sample - loss: 84.7732 - val_loss: 83.6995\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s 133us/sample - loss: 84.7966 - val_loss: 83.6407\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s 134us/sample - loss: 84.8375 - val_loss: 83.7389\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 84.8442 - val_loss: 83.6660\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 84.8507 - val_loss: 83.6052\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s 127us/sample - loss: 84.7327 - val_loss: 83.4541\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 84.7712 - val_loss: 83.6410\n"
     ]
    }
   ],
   "source": [
    "modelfit = model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
