{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**  A neuron is a single entity which takes and input and applies a function to the input and provides an output\n",
    "- **Input Layer:** Input Layer is a set of neurons whose input value is the values based on which training/prediction has to be performed\n",
    "- **Hidden Layer:** Hiddeng layers is a set of neurouns whose input is the output from the another layer in a neural network after the application of the activation function\n",
    "- **Output Layer:** Output layers is a set of neurons whose output values post the activation function is used to predict the outcome of the target.\n",
    "- **Activation:** It is a function which is applied on the dot product of weights and inputvalues of the neurons\n",
    "- **Backpropagation:** Backpropagation is a learning algorithm which calculates the error of the weights in so as to minimise the cost function of the learning algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "seed = 40\n",
    "np.random.seed(seed)\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. You will not be able to achieve more than ~50% with the simple perceptron. Explain why you could not achieve a higher accuracy with the *simple perceptron* architecture, because it's possible to achieve ~95% accuracy on this dataset. Provide your answer in markdown (and *optional* data anlysis code) after your perceptron implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2), (10000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start your candy perceptron here\n",
    "\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values.reshape(len(candy),1)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))\n",
    "\n",
    "def der_sigmoid(x):\n",
    "  sx = sigmoid(x)\n",
    "  return sx*(1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:0, MSE :0.25558\n",
      "Iteration:1, MSE :0.54885\n",
      "Iteration:2, MSE :0.32525\n",
      "Iteration:3, MSE :0.54885\n",
      "Iteration:4, MSE :0.32525\n",
      "Iteration:5, MSE :0.54885\n",
      "Iteration:6, MSE :0.32525\n",
      "Iteration:7, MSE :0.54885\n",
      "Iteration:8, MSE :0.32525\n",
      "Iteration:9, MSE :0.54885\n",
      "weights:[[388.52858339]\n",
      " [434.56783028]]\n",
      "Accuracy after training 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,accuracy_score\n",
    "weights = np.random.rand(2,1)\n",
    "error_rsm = 100\n",
    "\n",
    "for i in range(10):\n",
    "    weighted_sum = np.dot(X,weights)\n",
    "    activated = sigmoid(weighted_sum)\n",
    "    error = y - activated\n",
    "    adjusted = error*der_sigmoid(error)\n",
    "    weights += np.dot(X.T,adjusted)\n",
    "    error_rsm = mean_squared_error(y,activated)\n",
    "    #if (i%100==0):\n",
    "    print(f'Iteration:{i}, MSE :{error_rsm:0.5f}')\n",
    "print(f'weights:{weights}')\n",
    "predicted = (activated > 0.5).astype(int)\n",
    "print(f'Accuracy after training {accuracy_score(y,predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Perceptron \n",
    "\n",
    "Single perceptron are good for Identifying Lineral patterns. In the current Gummy Bear Dataset,the output based on the features which is gummy or choclate do not have a linear relationship. This dataset is similar to XOR gate which can be explained only by a polynomial equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propogate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)\n",
    "        return J\n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "        \n",
    "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(X.T, delta2)  \n",
    "        \n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    #Helper Functions for interacting with other classes:\n",
    "    def getParams(self):\n",
    "        #Get W1 and W2 unrolled into vector:\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        #Set W1 and W2 using single paramater vector.\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize * self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n",
    "        \n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "class trainer(object):\n",
    "    def __init__(self, N):\n",
    "        #Make Local reference to network:\n",
    "        self.N = N\n",
    "        \n",
    "    def callbackF(self, params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.X, self.y))   \n",
    "        \n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(X, y)\n",
    "        grad = self.N.computeGradients(X,y)\n",
    "        \n",
    "        return cost, grad\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        #Make an internal variable for the callback function:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        #Make empty list to store costs:\n",
    "        self.J = []\n",
    "        \n",
    "        params0 = self.N.getParams()\n",
    "\n",
    "        options = {'maxiter': 200, 'disp' : True}\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', \\\n",
    "                                 args=(X, y), options=options, callback=self.callbackF)\n",
    "\n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 256.295819\n",
      "         Iterations: 39\n",
      "         Function evaluations: 44\n",
      "         Gradient evaluations: 44\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "T = trainer(NN)\n",
    "T.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: \n",
      "0.05125916383849585\n",
      "The Accuracy score after Training on MLP is 0.9458\n"
     ]
    }
   ],
   "source": [
    "#print(\"Predicted Output: \\n\" + str(NN.forward(X))) \n",
    "print(\"MSE Loss: \\n\" + str(np.mean(np.square(y - NN.forward(X))))) # mean sum squared loss\n",
    "predicted = (NN.forward(X) > 0.5).astype(int)\n",
    "print(f'The Accuracy score after Training on MLP is {accuracy_score(y,predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "248   54    1   1       192   283    0        0      195      0      0.0   \n",
       "162   41    1   1       120   157    0        1      182      0      0.0   \n",
       "77    59    1   1       140   221    0        1      164      1      0.0   \n",
       "9     57    1   2       150   168    0        1      174      0      1.6   \n",
       "260   66    0   0       178   228    1        1      165      1      1.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "248      2   1     3       0  \n",
       "162      2   0     2       1  \n",
       "77       2   0     2       1  \n",
       "9        2   0     2       1  \n",
       "260      1   2     3       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (303, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preparing features and target data\n",
    "X = df[df.columns.drop('target')].values\n",
    "y = df['target'].values.reshape(len(df),1)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline prediction for the Heart is 54.455\n"
     ]
    }
   ],
   "source": [
    "#Baseling prediction\n",
    "print(f'Baseline prediction for the Heart is {(sum(y)*100/len(y))[0]:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardising input data\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 98        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 288\n",
      "Trainable params: 288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 272 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "272/272 [==============================] - 1s 4ms/sample - loss: 0.7244 - accuracy: 0.6103 - val_loss: 0.7628 - val_accuracy: 0.5484\n",
      "Epoch 2/10\n",
      "272/272 [==============================] - 0s 381us/sample - loss: 0.6429 - accuracy: 0.6471 - val_loss: 0.6852 - val_accuracy: 0.6129\n",
      "Epoch 3/10\n",
      "272/272 [==============================] - 0s 365us/sample - loss: 0.5827 - accuracy: 0.6985 - val_loss: 0.6318 - val_accuracy: 0.6452\n",
      "Epoch 4/10\n",
      "272/272 [==============================] - 0s 360us/sample - loss: 0.5391 - accuracy: 0.7721 - val_loss: 0.5950 - val_accuracy: 0.6774\n",
      "Epoch 5/10\n",
      "272/272 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.77 - 0s 370us/sample - loss: 0.5034 - accuracy: 0.7831 - val_loss: 0.5627 - val_accuracy: 0.6774\n",
      "Epoch 6/10\n",
      "272/272 [==============================] - 0s 355us/sample - loss: 0.4724 - accuracy: 0.8015 - val_loss: 0.5334 - val_accuracy: 0.7097\n",
      "Epoch 7/10\n",
      "272/272 [==============================] - 0s 370us/sample - loss: 0.4483 - accuracy: 0.8051 - val_loss: 0.5091 - val_accuracy: 0.7097\n",
      "Epoch 8/10\n",
      "272/272 [==============================] - 0s 344us/sample - loss: 0.4273 - accuracy: 0.8162 - val_loss: 0.4933 - val_accuracy: 0.7419\n",
      "Epoch 9/10\n",
      "272/272 [==============================] - 0s 359us/sample - loss: 0.4091 - accuracy: 0.8235 - val_loss: 0.4800 - val_accuracy: 0.7419\n",
      "Epoch 10/10\n",
      "272/272 [==============================] - 0s 357us/sample - loss: 0.3955 - accuracy: 0.8309 - val_loss: 0.4660 - val_accuracy: 0.7742\n"
     ]
    }
   ],
   "source": [
    "#Base Model\n",
    "model = Sequential()\n",
    "model.add(Dense(13,input_shape=(13,),activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "# Output Layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam', \n",
    "                    metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(X, y, batch_size=10,epochs=10, validation_split=.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 64us/sample - loss: 0.4158 - accuracy: 0.8383\n",
      "The Accuracy score after training is: 83.82838368415833\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, y)\n",
    "print(f'The Accuracy score after training is: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8415841438589317 using {'batch_size': 20, 'epochs': 100, 'optimizer': 'adam'}\n",
      "Means: 0.8052805288396653, Stdev: 0.015859070476382686 with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'adam'}\n",
      "Means: 0.8118811916596819, Stdev: 0.003921189410517012 with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'sgd'}\n",
      "Means: 0.8118811637261519, Stdev: 0.009280184034149026 with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'adam'}\n",
      "Means: 0.8085808724460035, Stdev: 0.013833149436226303 with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'sgd'}\n",
      "Means: 0.83498347730133, Stdev: 0.0005446046733229049 with: {'batch_size': 20, 'epochs': 50, 'optimizer': 'adam'}\n",
      "Means: 0.726072631850101, Stdev: 0.028799078977137058 with: {'batch_size': 20, 'epochs': 50, 'optimizer': 'sgd'}\n",
      "Means: 0.8415841438589317, Stdev: 0.006077882329109475 with: {'batch_size': 20, 'epochs': 100, 'optimizer': 'adam'}\n",
      "Means: 0.8052805243152203, Stdev: 0.017144407838522533 with: {'batch_size': 20, 'epochs': 100, 'optimizer': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameter tuning using Grid Search CV\n",
    "\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,input_shape=(13,),activation='relu'))\n",
    "    model.add(Dense(7, activation='relu'))\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                        optimizer=optimizer, \n",
    "                        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "param_grid = {'batch_size': [10,20],\n",
    "              'epochs': [50,100],\n",
    "              'optimizer':['adam','sgd']\n",
    "            }\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1,cv=2,verbose=0)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
